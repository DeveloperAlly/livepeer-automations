export const ghostData = [
{
  title: `A Real-time Update to the Livepeer Network Vision`,
  href: `https://blog.livepeer.org/a-real-time-update-to-the-livepeer-network-vision/`,
  author: `By Livepeer Team`,
  content: `<p>For the past year, the Livepeer Ecosystem has been guided by the <a href="https://blog.livepeer.org/introducing-livepeer-cascade-a-vision-for-livepeers-future-in-the-age-of-real-time-ai-video/"><u>Cascade vision</u></a>:&nbsp; a path to transition from a pure streaming and transcoding infrastructure, to an infrastructure that could succeed at providing compute for the future of real-time AI video. The latest Livepeer <a href="https://messari.io/report/state-of-livepeer-q3-2025?ref=blog.livepeer.org"><u>quarterly report from Messari</u></a> highlights that this transition is paying off, with network fees up 3x from this time last year, and over 72% of the fees now driven via AI inference. This is exemplified by the growing inspirational examples emerging from <a href="http://daydream.live/?ref=blog.livepeer.org"><u>Daydream powered real-time AI</u></a>, and real-time Agent avatar generation through Embody and the Agent SPE. </p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.livepeer.org/content/images/2025/11/Screenshot-2025-10-17-at-15.35.29.png" class="kg-image" alt="" loading="lazy" width="1200" height="672" srcset="https://blog.livepeer.org/content/images/size/w600/2025/11/Screenshot-2025-10-17-at-15.35.29.png 600w, https://blog.livepeer.org/content/images/size/w1000/2025/11/Screenshot-2025-10-17-at-15.35.29.png 1000w, https://blog.livepeer.org/content/images/2025/11/Screenshot-2025-10-17-at-15.35.29.png 1200w" sizes="(min-width: 720px) 720px"><figcaption><i><em class="italic" style="white-space: pre-wrap;">Source: </em></i><a href="https://messari.io/report/state-of-livepeer-q3-2025?ref=blog.livepeer.org"><u><i><em class="italic underline" style="white-space: pre-wrap;">Livepeer Q3 2025 Report</em></i></u></a><i><em class="italic" style="white-space: pre-wrap;"> by Messari</em></i></figcaption></figure><p>This shift has been an ecosystem wide effort ‚Äì ranging from branding and communications, to productization and go to market, to hardware upgrades for orchestrators. It has successfully shifted the project under an updated mission and direction, however it has still left ambiguity in terms of what the Livepeer network itself offers as killer value propositions to new builders outside of the existing ecosystem. Is it a GPU cloud? A transcoding infra? An API engine? Now that there are signs of validation and accelerated momentum around an exciting opportunity, it‚Äôs time to really hone in on a refined vision for the future of the Livepeer network as a product itself.&nbsp;</p><h3 id="the-market-for-video-is-set-to-massively-expand">The market for video is set to massively expand</h3><p>The concept of live video itself is expanding well beyond a simple single stream of video captured from a camera. Now entire worlds and scenes are generated or enhanced in real-time via AI assistance, leading to more immersive and interactive experiences than possible via old-school streaming alone. For a taste of the future, see the following examples:</p><ol><li>The future of gaming will be AI generated video and worlds in real-time: </li></ol><figure class="kg-card kg-embed-card"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">AI games are going to be amazing<br><br>(sound on) <a href="https://t.co/66aOdWJr4Y?ref=blog.livepeer.org">pic.twitter.com/66aOdWJr4Y</a></p>‚Äî Matt Shumer (@mattshumer_) <a href="https://twitter.com/mattshumer_/status/1981406315693187430?ref_src=twsrc%5Etfw&ref=blog.livepeer.org">October 23, 2025</a></blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></figure><ol start="2"><li>Video streams can be analyzed and data leveraged programmatically in real-time, for instant insight generation and decision making:</li></ol><figure class="kg-card kg-embed-card"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">3 years since I joined roboflow<br><br>- 68k stars on github<br>- 60 videos and streams on youtube<br>- 2.5M views in total<br>- 40 technical blogposts<br><br>‚Üì coolest stuff I made <a href="https://t.co/EMy5qWq1Vp?ref=blog.livepeer.org">pic.twitter.com/EMy5qWq1Vp</a></p>‚Äî SkalskiP (@skalskip92) <a href="https://twitter.com/skalskip92/status/1983585881865982149?ref_src=twsrc%5Etfw&ref=blog.livepeer.org">October 29, 2025</a></blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></figure><ol start="3"><li>Real-time style transfer can enable avatars and agents to participate in the global economy:</li></ol><figure class="kg-card kg-embed-card"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">üá®üá≥ We‚Äôre screwed ‚Ä¶ it becomes indistinguishable from reality<br><br>Ali‚Äôs Wan 2.2 lets you stream without showing your face. It maps your voice and motion onto another face. <a href="https://t.co/iD4nQIVaRY?ref=blog.livepeer.org">pic.twitter.com/iD4nQIVaRY</a></p>‚Äî Lord Bebo (@MyLordBebo) <a href="https://twitter.com/MyLordBebo/status/1983846299586683236?ref_src=twsrc%5Etfw&ref=blog.livepeer.org">October 30, 2025</a></blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></figure><p>Video world models and real-time AI video are merging, as they both use AI to generate frame-by-frame video output with low latency on the fly, based on user input and AI inference. This requires a tremendous amount of GPU compute, and requires an amazing low latency video streaming and compute stack ‚Äì two areas in which the Livepeer network and community thrive, and two areas to which the many other generic GPU inference providers in the market bring no unique skillset, experience, or software advantage.&nbsp;</p><p><strong>The big opportunity for the Livepeer network is to be the leading AI Infrastructure For Real-Time Video. </strong><br>From interactive live streaming to generative world models, Livepeer‚Äôs open-access, low-latency network of GPUs will be the best compute solution for cutting edge AI video workflows.&nbsp;</p><p>World models are a game changing category, and Livepeer is well suited to offer a unique and differentiated product here, that serves a huge market of diverse and varying use cases. These range from creative entertainment, to gaming, to robotics, to data analysis, to monitoring and security, to synthetic data generation for AGI itself. </p><figure class="kg-card kg-image-card"><img src="https://blog.livepeer.org/content/images/2025/11/Real-time-AI-Opportunities-by-Industry-2.png" class="kg-image" alt="" loading="lazy" width="1350" height="1080" srcset="https://blog.livepeer.org/content/images/size/w600/2025/11/Real-time-AI-Opportunities-by-Industry-2.png 600w, https://blog.livepeer.org/content/images/size/w1000/2025/11/Real-time-AI-Opportunities-by-Industry-2.png 1000w, https://blog.livepeer.org/content/images/2025/11/Real-time-AI-Opportunities-by-Industry-2.png 1350w" sizes="(min-width: 720px) 720px"></figure><p>While an ambitious stretch, Nvidia executives responsible for the category have even projected that due to the impact in robotics, <a href="https://arstechnica.com/ai/2025/09/big-ai-firms-pump-money-into-world-models-as-llm-advances-slow/?ref=blog.livepeer.org#:~:text=Both%20Niantic%20and%20Nvidia%20are,work%2C%E2%80%9D%20said%20Nvidia's%20Lebaredian."><u>the economic opportunity for world models could exceed $100 trillion</u></a>, or approximately the size of the entire global economic output itself!&nbsp;&nbsp;</p><p><strong>What does it mean to productize the Livepeer network to succeed as a valuable infrastructure in this category?</strong> <br><br>From a simplified viewpoint, it needs to deliver on the following:</p><p>1. Ability for users to deploy real-time AI workflows to the Livepeer network and request inference on them</p><p>2. Industry leading latency for providing inference on real-time AI and world model workflows.</p><p>3. Cost effective scalability ‚Äì users can pay as they go to scale up and down capacity and the network automagically delivers the scale required.</p><p>Imagine a gaming platform is powering world-model generated games using their unique workflows that generate game levels or areas in a certain style by combining several real-time models, LLMs, and style transfer mechanisms. Each game its powering has users exploring and creating their own corners of the interactive worlds, based on prompts and gameplay inputs. Every gamer that joins a game represents a new stream of AI video compute, and the Livepeer network is the backing infrastructure that provides the compute for this video world generation, leveraging hundreds or thousands of GPUs concurrently.</p><p>For this to be possible the Livepeer network needs to enable that game platform to deploy their game generation workflow. It needs to offer low latency on the inference that runs this workflow, relative to the generic GPU compute clouds. The pricing needs to be competitive vs alternative options in the market for this GPU compute. And the network needs to allow this company to scale up and down the number of GPUs that are currently live ready to accept new real-time inference streams based on the number of users currently live on the games it is powering.</p><p>All of this is possible on the Livepeer network, and it isn‚Äôt far away from where we are now. If we work to build, test, and iterate on the Livepeer network itself towards supporting the latency and scale required for these types of workflows, we‚Äôll be set up to power them.<br>Now multiply this example gaming company by the high number of diverse industries and verticals that real-time AI and world models will touch. Each category can have one or multiple companies competing to leverage this scalable and cost effective infrastructure for unique go to markets targeting different segments. And they can all be powered by the Livepeer network‚Äôs unique value propositions.</p><h3 id="livepeer%E2%80%99s-core-network-is-strategically-positioned">Livepeer‚Äôs core network is strategically positioned</h3><p>What are these value propositions that make the Livepeer network differentiated relative to alternative options in the market? I‚Äôd argue that there are three primary, table stakes, must-have value propositions if Livepeer is to succeed.&nbsp;</p><p>1.&nbsp;<strong>Industry standard low latency infrastructure specializing in real-time AI and world model workflows:</strong> First of all, the network needs to let its users deploy custom workflows. Inference alone on base models is not enough and does not represent scaled demand. Users want to take base models, chain them together with other models and pre/post processors, and create unique and specialized capabilities. When one of these capabilities is defined as a workflow, that is the unit that needs to be deployed as a job on the Livepeer network, and the network needs to be able to run inference on it. Secondly, for these real-time interactive use cases, latency matters a lot. Generic GPU clouds don‚Äôt offer the specialized low latency video stacks to ingest, process, and serve video with optimal latency, but Livepeer does. And Livepeer needs to benchmark itself to have lower or equal latency to alternative GPU clouds for these particular real-time and world model use cases.</p><p>2.&nbsp;<strong>Cost effective scalability:</strong> GPU provisioning, reservations, and competing for scarce supply procurement creates major challenges for AI companies ‚Äì often overpaying for GPUs that sit idle most of the time in order to guarantee the capacity that they need. The Livepeer network‚Äôs value proposition is that users should be able to ‚Äúautomagically‚Äù scale up almost instantly and pay on demand for the compute that they use, rather than having to pre-pay for reservations and let capacity sit idle. This is enabled by Livepeer taking advantage of otherwise existing idle longtail compute through its open marketplace, and its supply side incentives. The Livepeer network needs to be more cost effective than alternative GPU clouds within this category - with impacts comparable to the 10x+ cost reduction already demonstrated in live video transcoding delivered by the network.</p><p><strong>3. Community driven, open source, open access:</strong> The Livepeer project and software stack is open source. Users can control, update, and contribute to the software they are using. They also can be owners in the infrastructure itself through the Livepeer Token, and can benefit from the network‚Äôs improvements and adoption, creating a network effect. The community that cares about its success and pushes it forward collectively, can be a superpower, relative to the uncertain and shaky relationship between builders and centralized platform providers, who have a history of getting rugged based on limitations to access, changes in functionality, or discontinuity of the platforms. Anyone can build on the Livepeer network regardless of location, jurisdiction, use case, or central party control.</p><p>The above are primary value propositions that should appeal to nearly all users. And we must work to close the gaps to live up to those value props before we could successfully hope to go to market and attract new vertical-specific companies to build directly on top of the network. Luckily, in addition to all of Livepeer‚Äôs streaming users, we have a great realtime AI design partner in <a href="http://daydream.live/?ref=blog.livepeer.org"><u>Daydream</u></a>, which is already going to market around creative real-time AI, using the network, and contributing to its development to live up to these requirements. While building with this design partner, the ecosystem should be working to productize to live up to these promises in a more generic perspective ‚Äì it should be setting up benchmarks, testing frameworks, and building mechanisms for scaling up supply ahead of demand, so that it can represent this power to the world alongside successful Daydream case studies.</p><h3 id="opportunities-to-push-towards-this-vision">Opportunities to push towards this vision</h3><p>To truly live up to these value propositions, there are a number of opportunities for the community to focus on in order to close some key gaps. There are many details to come in more technical posts laying out roadmaps and execution frameworks, but at a high level, consider a series of milestones that take the network as a product from technically functional, to production usable, to extensible, to infinitely scalable:</p><ol><li><strong>Network MVP - Measure what matters: </strong>Establish key network performance SLAs, measure latency and performance benchmarks, and enhance the low latency client to support realtime AI workflows above industry grade standards. </li><li><strong>Network as a Product - Self adaptability and scalability: </strong>Network delivers against these SLAs and core value props for supported realtime AI workflows. Selection algorithms, failovers and redundancy, and competitive market price discovery established for realtime AI. </li><li><strong>Extensibility - Toolkit for community to deploy workflows and provision resources:</strong> Workflow deployment and signaling, LPT incentive updates to ensure compute supply for popular AI workflows exceeds demand.</li><li><strong>Parallel Scalability: </strong>Manage clusters of resources on the network for parallel workflow execution, truly unlocking job types beyond single-GPU inference.&nbsp;</li></ol><p>Many teams within the ecosystem, from the Foundation, to Livepeer Inc, to various SPEs have already started operationalizing around how they‚Äôll be contributing to milestones 1 and 2 to upgrade the network to deliver against these key realtime AI value propositions.<strong>&nbsp;</strong></p><h3 id="conclusion-and-livepeer%E2%80%99s-opportunity">Conclusion and Livepeer‚Äôs opportunity</h3><p><strong>&nbsp;</strong>The market for the opportunity to be the GPU infrastructure that powers real-time AI and world models is absolutely massive ‚Äì the compute requirements are tremendous - 1000x that of AI text or images - and real-time interaction with media represents a new platform that will affect all of the above-mentioned industries. The Livepeer network can be the infrastructure that powers it. How we plan to close the needed gaps and achieve this will be the subject of an upcoming post. But when we do prove these value propositions, <strong>Livepeer will have a clear path to 100x the demand on the network</strong>.&nbsp;</p><p>The likely target market users for the network are those startups that are building out vertical specific businesses on top of real-time AI and world model workflows. The ecosystem should look to enable one (or multiple!) startups in each category going after building real-time AI platforms that serve gaming, that serve robotics, that serve synthetic data generation, that serve monitoring and analysis, and all the additional relevant categories. The network‚Äôs value propositions will hopefully speak for themselves, but in the early stages of this journey, it is likely the ecosystem will want to use incentives (like investment or credits) to bootstrap these businesses into existence. Each will represent a chance at success, and will bring more demand and proof.</p><p>Ultimately, many users of these platforms may choose to build direct on the network themselves. Similarly to how startups start to build on platforms like Heroku, Netlify, or Vercel, and then as they scale and need more control and cost savings they build direct on AWS, and then ultimately move to their own datacenters after reaching even more scale ‚Äì users of Daydream or a real-time Agent platform built on Livepeer, may ultimately choose to run their own gateways to recognize the cost savings and control and full feature set that comes from doing so. This is a good thing! As it represents even more usage and scale for the network, more proof that as an infrastructure the Livepeer network has product market fit, and that it can absorb all workflows directly. The businesses built on top will provide their own vertical specific bundles of features and services that onboard that vertical specific capacity, but they‚Äôll be complemented by and enabled by the Livepeer Network‚Äôs superpowers.</p><p>While there‚Äôs a lot of work ahead, the Livepeer community has already stepped up to cover tremendous ground on this mission. At the moment by already powering millions of minutes of real-time AI inference per week, by our orchestrators already upgrading their capacity and procurement mechanisms to provide real-time AI-capable compute, and by the Foundation groups already working to evaluate the networks incentives and cryptoeconomics to sustainably fund and reward those contributing to this effort, we‚Äôre set up well to capture this enormous opportunity!</p>`,
  datePosted: `Nov 13, 2025`,
  img: `https://blog.livepeer.org/content/images/2025/11/LP_Blog-Header_Nov25_01_moshed-1.png`,
  excerpt: `For the past year, the Livepeer Ecosystem has been guided by the Cascade vision:¬† a path to transition from a pure streaming and transcoding infrastructure, to an infrastructure that could succeed at providing compute for the future of real-time AI video. The latest Livepeer quarterly report from Messari highlights that this transition is paying off, with network fees up 3x from this time last year, and over 72% of the fees now driven via AI inference. This is exemplified by the growing inspirat`,
  reading_time: 9
},
{
  title: `Livepeer Onchain Builders - Streamplace: Building the Video Backbone of Decentralized Social`,
  href: `https://blog.livepeer.org/livepeer-onchain-builders-streamplace-building-the-video-backbone-of-decentralized-social/`,
  author: `By Livepeer Team`,
  content: `<p>Welcome to Livepeer Onchain Builders, a new content series spotlighting the Special Purpose Entities (SPEs) funded by the Livepeer onchain treasury. SPEs are working groups funded by the community treasury to work on specific tasks and are accountable to the community for their delivery. These deep dives will explore how each initiative is driving protocol usage, expanding infrastructure, and pushing the boundaries of what‚Äôs possible in decentralized video and AI.</p><p>Streamplace is an open-source video streaming platform designed to power decentralized social applications with real-time, creator-first infrastructure. It aims to make livestreaming and video hosting as seamless as TikTok or YouTube, but built on open protocols and self-sovereign identity.</p><p>What makes it ambitious? Streamplace is not only building full-stack video infra for federated social networks, it's doing so in a way that prioritizes interoperability, scalability, and public goods. From developer SDKs to end-user apps, Streamplace is building an entire ecosystem.</p><h2 id="what-is-an-spe"><strong>What is an SPE?&nbsp;</strong></h2><p>A Special Purpose Entity (SPE) is a focused, community-funded team contributing to the Livepeer ecosystem. SPEs are typically mission-driven groups that operate independently to build infrastructure, applications, or tooling that expand and improve the Livepeer protocol. These teams are funded through proposals to the onchain treasury and are accountable to the community.</p><p>SPEs are necessary for the ecosystem because no single team can build every part of a decentralized protocol. SPEs decentralize development, fund public goods, and allow the community to direct resources where they're most needed.</p><p>Why do they matter to delegators and stakeholders? Because SPEs grow in usage. More usage = more fees = more rewards. Delegators benefit when the protocol succeeds, and SPEs are among the most direct ways to make that happen.</p><h2 id="from-aquareum-to-streamplace"><strong>From Aquareum to Streamplace</strong></h2><p>A clear goal drives the team behind Streamplace: to build the foundational video infrastructure for the next generation of decentralized social platforms. These platforms, such as Farcaster and the AT Protocol, promise user-owned identity and interoperability, but have thus far lacked robust support for live and on-demand video.</p><p>Streamplace solves this by providing a full-stack, developer-friendly video layer that anyone can plug into. It's a bold attempt to make decentralized video feel as native and easy as its Web2 counterparts.</p><p>Streamplace started as Aquareum, a project with the same mission and team. This evolution into Streamplace is a rebranding, not a restart, building on past momentum with a sharper focus.</p><p>Their vision is to give every user the ability to publish, stream, and remix content with the same ease as TikTok or YouTube, but backed by self-sovereign identity and decentralized networks.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdOnanmhGKm119MEuYb_rYoVaOoSSLh50HhwTV6W2MLwVMd34id-nkFoXxQ3yo2GOOsOW4X2k4M8LiWNtNcMfHED6O4xYF9FIzTrFM2n9vN0Zfh9T6nRROsnGF7D46RmeSwxY1exA?key=vwSQtFAdQmFDSkDCS6FNzw" class="kg-image" alt="" loading="lazy" width="606" height="293"><figcaption><i><em class="italic" style="white-space: pre-wrap;">Streamplace homepage</em></i></figcaption></figure><p>The first proposal delivered:</p><ul><li>A unified Aquareum node: bundling the Livepeer stack with indexing and playback.</li><li>App releases on iOS, Android, and Web.</li><li>Native integrations with AT Protocol and Farcaster.</li><li>Support for C2PA metadata and content provenance.</li></ul><p>Now, Streamplace continues that momentum with 100,000 LPT in treasury funding and a clear mandate to scale.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfcbwXcvbCUOYbmulwb1P-GioWPVSQ_-lhxOdH1b4PY5l7IUvYTyqj7R0zrWj2V480VfZPHyKBNgw0P690Pa3Z3Ai_l-li9LyZrCID1z4AyHZHPGHcDG7C-Jh8qYyFI9kwCHWavrQ?key=vwSQtFAdQmFDSkDCS6FNzw" class="kg-image" alt="" loading="lazy" width="624" height="300"><figcaption><i><em class="italic" style="white-space: pre-wrap;">Streamplace Graphana dashboard</em></i></figcaption></figure><h2 id="why-streamplace-matters"><strong>Why Streamplace Matters</strong></h2><p>Video is the heart of online social interaction. Yet decentralized social networks have lagged in providing seamless, user-friendly video experiences. Streamplace addresses this by:</p><ul><li><strong>Transcoding every livestream through Livepeer</strong>, providing decentralized, low-cost processing for global delivery.</li><li><strong>Powering partner platforms like Skylight Social</strong>, a TikTok alternative backed by Mark Cuban, that recently hit #1 in entertainment on the App Store.</li><li><strong>Making it dead-simple to stream or host video</strong> through single-binary nodes that anyone can deploy.</li><li><strong>Championing public goods</strong>, 100% of their code is open source, with a commitment to infrastructure, not monetization lock-in.</li></ul><p>Decentralized social, spanning protocols like Farcaster, AT Protocol, and Bluesky, represents a movement toward user-owned networks and open standards. These networks are gaining traction, but video remains a missing layer. That‚Äôs where Streamplace comes in.</p><p>Video is essential because it's the most engaging, expressive medium for creators and communities. And as these decentralized platforms scale, having real-time, composable video becomes non-negotiable.</p><p>Streamplace positions itself as the default video infra layer for this new social stack, and with every stream transcoded through Livepeer, it's also a major driver of protocol usage and visibility.</p><h2 id="what-streamplace-20-will-deliver"><strong>What Streamplace 2.0 Will Deliver</strong></h2><p>This new phase of work, funded by the Livepeer treasury, focuses on scale, performance, and ecosystem integration:</p><h3 id="infrastructure-enhancements"><strong>Infrastructure Enhancements</strong></h3><ul><li>Expand server capacity to support growing user bases like Skylight.</li><li>Harden video nodes for reliability under real-world load.</li><li>Deliver high-quality performance on all platforms: Web, iOS, Android.</li></ul><h3 id="protocol-and-developer-growth"><strong>Protocol and Developer Growth</strong></h3><ul><li>Deepen native integration with AT Protocol.</li><li>Build SDKs and NPM packages to embed Streamplace easily into other apps.</li><li>Ship VOD functionality and new moderation tools.</li></ul><h3 id="community-first-ethos"><strong>Community-First Ethos</strong></h3><ul><li>Launch creator monetization models and stream incentive programs.</li><li>Empower streamers with self-hosted app capabilities ("Twitch, but it's your own app").</li><li>Maintain full transparency and livestream development.</li></ul><h2 id="the-livepeer-angle"><strong>The Livepeer Angle</strong></h2><p>Livepeer's decentralized video infrastructure powers every second of video on Streamplace. That means more work for orchestrators, more fees flowing through the protocol, and more incentive for high-quality node operation.</p><p>Streamplace strengthens the Livepeer ecosystem in three key ways:</p><ul><li><strong>Demand generation</strong>: Real-world usage at scale means more consistent transcoding work.</li><li><strong>Protocol visibility</strong>: High-impact apps like Skylight drive awareness of Livepeer beyond its native circles.</li><li><strong>Infrastructure robustness</strong>: Streamplace's nodes enhance the distributed capacity of the Livepeer network.</li></ul><p>Without Livepeer, a decentralized video stack like Streamplace wouldn‚Äôt be possible. And without ambitious apps like Streamplace, Livepeer wouldn‚Äôt have the same opportunity to prove its value at scale.</p><h2 id="final-thoughts"><strong>Final Thoughts</strong></h2><p>Streamplace is a keystone piece of open video infrastructure and a cornerstone in the emerging world of decentralized social media. By fusing creator-first tooling with Livepeer‚Äôs scalable infrastructure, it offers a glimpse into what the open internet can become.</p><p>As decentralized protocols shift from vision to adoption, the need for native video is urgent. Streamplace, with the support of the Livepeer treasury and a relentless commitment to open-source infrastructure, is meeting that need head-on.</p><p>If you're a developer, creator, or community builder, now is the time to get involved.</p><p>Do you want to contribute to Streamplace's success? Explore the open roles <a href="https://jobs.stream.place/?ref=blog.livepeer.org"><u>here</u></a>.</p><p>Interested in building or contributing to the Livepeer ecosystem? Learn more about current and past SPEs, open opportunities, and how to submit your own proposal <a href="https://livepeer.notion.site/Livepeer-Governance-Hub-13d0a348568780a598acc869d19f14c8?ref=blog.livepeer.org"><u>here</u></a>.</p><p>Follow along, fork the code, or join a stream ‚Äî the future of social video is open.</p><h3 id="links"><strong>Links</strong></h3><p><a href="https://app.stream.place/?ref=blog.livepeer.org"><u>Streamplace App</u></a></p><p><a href="https://explorer.livepeer.org/treasury/69979842640287825025581148561220268429620025129899844442017200219379700175479?ref=blog.livepeer.org"><u>Streamplace Proposal</u></a></p><p><a href="https://explorer.livepeer.org/treasury/74518185892381909671177921640414850443801430499809418110611019961553289709442?ref=blog.livepeer.org"><u>Aquareum Proposal</u></a></p><p></p><hr><p>Livepeer is a decentralized video infrastructure network for live and on-demand streaming. It has integrated AI Video Compute capabilities (Livepeer AI) by harnessing its massive GPU network and is not building the future of real-time AI video.</p><p><a href="https://x.com/Livepeer?ref=blog.livepeer.org"><u>Twitter</u></a> | <a href="https://discord.com/invite/livepeer?ref=blog.livepeer.org"><u>Discord</u></a> | <a href="https://www.livepeer.org/?ref=blog.livepeer.org"><u>Website</u></a></p>`,
  datePosted: `Aug 14, 2025`,
  img: `https://blog.livepeer.org/content/images/2025/08/Onchain-Builders-Streamplace.jpg`,
  excerpt: `Welcome to Livepeer Onchain Builders, a new content series spotlighting the Special Purpose Entities (SPEs) funded by the Livepeer onchain treasury. SPEs are working groups funded by the community treasury to work on specific tasks and are accountable to the community for their delivery. These deep dives will explore how each initiative is driving protocol usage, expanding infrastructure, and pushing the boundaries of what‚Äôs possible in decentralized video and AI.

Streamplace is an open-source `,
  reading_time: 5
},
{
  title: `Builder Story: dotsimulate x Daydream`,
  href: `https://blog.livepeer.org/builder-story-dotsimulate-x-daydream/`,
  author: `By Livepeer Team`,
  content: `<p><strong>Building StreamDiffusionTD Operator - a Real-Time Generative Video Operator for TouchDesigner, Powered by the Daydream API<br><br>Creator:</strong> Lyell Hintz (<a href="https://x.com/dotsimulate?ref=blog.livepeer.org" rel="noreferrer">@dotsimulate</a>)<br><strong>Operator:</strong> StreamDiffusionTD<br><strong>Backends Supported:</strong> Local + Daydream (Livepeer)</p><figure class="kg-card kg-video-card kg-width-regular" data-kg-thumbnail="https://blog.livepeer.org/content/media/2025/08/Daydream-Demo-2_thumb.jpg" data-kg-custom-thumbnail="">
            <div class="kg-video-container">
                <video src="https://blog.livepeer.org/content/media/2025/08/Daydream-Demo-2.mp4" poster="https://img.spacergif.org/v1/1920x1080/0a/spacer.png" width="1920" height="1080" playsinline="" preload="metadata" style="background: transparent url('https://blog.livepeer.org/content/media/2025/08/Daydream-Demo-2_thumb.jpg') 50% 50% / cover no-repeat;"></video>
                <div class="kg-video-overlay">
                    <button class="kg-video-large-play-icon" aria-label="Play video">
                        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                            <path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"></path>
                        </svg>
                    </button>
                </div>
                <div class="kg-video-player-container">
                    <div class="kg-video-player">
                        <button class="kg-video-play-icon" aria-label="Play video">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                                <path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"></path>
                            </svg>
                        </button>
                        <button class="kg-video-pause-icon kg-video-hide" aria-label="Pause video">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                                <rect x="3" y="1" width="7" height="22" rx="1.5" ry="1.5"></rect>
                                <rect x="14" y="1" width="7" height="22" rx="1.5" ry="1.5"></rect>
                            </svg>
                        </button>
                        <span class="kg-video-current-time">0:00</span>
                        <div class="kg-video-time">
                            /<span class="kg-video-duration">0:34</span>
                        </div>
                        <input type="range" class="kg-video-seek-slider" max="100" value="0">
                        <button class="kg-video-playback-rate" aria-label="Adjust playback speed">1√ó</button>
                        <button class="kg-video-unmute-icon" aria-label="Unmute">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                                <path d="M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z"></path>
                            </svg>
                        </button>
                        <button class="kg-video-mute-icon kg-video-hide" aria-label="Mute">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                                <path d="M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z"></path>
                            </svg>
                        </button>
                        <input type="range" class="kg-video-volume-slider" max="100" value="100">
                    </div>
                </div>
            </div>
            
        </figure><p><strong>Overview</strong></p><p>StreamDiffusionTD is a TouchDesigner operator that connects real-time inputs like audio, sensors, and camera feeds to StreamDiffusion, enabling live generative visuals controlled in real time. With the Daydream API, it adds remote inference capabilities on top of the existing local GPU inference and unlocks more flexibility for users.</p><p>Built by Lyell Hintz, a technical artist and TouchDesigner developer, the operator is used in live shows, installations, and experimental workflows.</p><p><strong>Why It Was Built</strong></p><p>Lyell began working on the operator a few hours after StreamDiffusion was released on GitHub. He wanted to use it in TouchDesigner - a powerful tool for real time interactive content creation.</p><p><strong>‚ÄúTouchDesigner is the only place this could be controlled from‚Ä¶ it can hook into everything else.‚Äù</strong></p><p>From the start, he avoided creating a ‚Äúblack box.‚Äù The operator exposes core parameters like prompt, seed, and ControlNet weights, allowing users to adjust values and see results immediately.</p><p><strong>Key Features</strong></p><ul><li>Real-time video generation</li><li>Prompt and seed morphing</li><li>Dynamic ControlNet weighting</li><li>Live input support: audio, sensors, camera</li><li>Local GPU and Daydream backend options</li><li>Instant visual feedback in TouchDesigner</li></ul><figure class="kg-card kg-video-card kg-width-regular" data-kg-thumbnail="https://blog.livepeer.org/content/media/2025/08/SD---Plugin--w_music-_thumb.jpg" data-kg-custom-thumbnail="">
            <div class="kg-video-container">
                <video src="https://blog.livepeer.org/content/media/2025/08/SD---Plugin--w_music-.mp4" poster="https://img.spacergif.org/v1/1920x1080/0a/spacer.png" width="1920" height="1080" playsinline="" preload="metadata" style="background: transparent url('https://blog.livepeer.org/content/media/2025/08/SD---Plugin--w_music-_thumb.jpg') 50% 50% / cover no-repeat;"></video>
                <div class="kg-video-overlay">
                    <button class="kg-video-large-play-icon" aria-label="Play video">
                        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                            <path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"></path>
                        </svg>
                    </button>
                </div>
                <div class="kg-video-player-container">
                    <div class="kg-video-player">
                        <button class="kg-video-play-icon" aria-label="Play video">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                                <path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"></path>
                            </svg>
                        </button>
                        <button class="kg-video-pause-icon kg-video-hide" aria-label="Pause video">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                                <rect x="3" y="1" width="7" height="22" rx="1.5" ry="1.5"></rect>
                                <rect x="14" y="1" width="7" height="22" rx="1.5" ry="1.5"></rect>
                            </svg>
                        </button>
                        <span class="kg-video-current-time">0:00</span>
                        <div class="kg-video-time">
                            /<span class="kg-video-duration">0:26</span>
                        </div>
                        <input type="range" class="kg-video-seek-slider" max="100" value="0">
                        <button class="kg-video-playback-rate" aria-label="Adjust playback speed">1√ó</button>
                        <button class="kg-video-unmute-icon" aria-label="Unmute">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                                <path d="M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z"></path>
                            </svg>
                        </button>
                        <button class="kg-video-mute-icon kg-video-hide" aria-label="Mute">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                                <path d="M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z"></path>
                            </svg>
                        </button>
                        <input type="range" class="kg-video-volume-slider" max="100" value="100">
                    </div>
                </div>
            </div>
            
        </figure><p><strong>Daydream API Integration</strong></p><p>StreamDiffusionTD works with the Daydream API, which allows the operator to run on a remote GPU backend. This eliminates the major barrier of requiring a high-end PC with an NVIDIA RTX 4090 to run StreamDiffusion at professional quality, unlocking the flexibility to run it from any location, on any device form factor.</p><figure class="kg-card kg-embed-card"><iframe width="200" height="113" src="https://www.youtube.com/embed/CANAMxabbRQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="" title="StreamDiffusionTD Updates // Daydream (non-local) Realtime Diffusion v0.2.99"></iframe></figure><p>Just drop in your API key and hit ‚ÄúStart Stream.‚Äù The backend handles orchestration, model hosting, and frame delivery, so builders can stay focused on their creative and technical workflows.</p><p>Setup takes less than 1 minute and once installed, the configuration is remembered for future use.Daydream‚Äôs API brings new features to StreamDiffusion:</p><ul><li><strong>Multi-controlnet</strong>: Mixing different controlnets for better artistic control</li><li><strong>IPAdapter</strong>: Use images as powerful style guides</li><li><strong>TensorRT</strong>: Better frame rate for smooth video output</li></ul><p>Daydream is adding support for more real time video generation models, and developers can request features, suggest improvements, or build on top of the API itself. It aligns with the values of open tooling and community-led infrastructure.</p><p><strong>How Artists can use StreamDiffusionTD in TouchDesigner</strong></p><ul><li>Audio-reactive visuals for concerts</li><li>Camera-driven generative visuals</li><li>Real-time visuals for LED walls and stages</li><li>TouchDesigner automation workflows</li></ul><p>Because it's built inside TouchDesigner, the operator can be extended using Python, MIDI, OSC, or any other input TouchDesigner supports.</p><p><strong>Current State</strong></p><p>The operator is live and ready to use, with active development underway for new features and improved performance. It‚Äôs a great time to jump in, explore, and help shape what comes next.</p><p><strong>Try it Yourself</strong></p><p>Operator Access: <a href="https://patreon.com/dotsimulate?ref=blog.livepeer.org" rel="noreferrer">patreon.com/dotsimulate</a><br>Community and Support: <a href="https://discord.gg/daydreamlive?ref=blog.livepeer.org" rel="noreferrer">discord.gg/daydreamlive</a><br>API Keys can be requested <a href="https://3o1go.share.hsforms.com/2qZbex9IHSZSgFcdumjx_ng?ref=blog.livepeer.org" rel="noreferrer">here</a></p>`,
  datePosted: `Aug 5, 2025`,
  img: `https://blog.livepeer.org/content/images/2025/08/DD_Builder-Story_dotsimulate_01.png`,
  excerpt: `Building StreamDiffusionTD Operator - a Real-Time Generative Video Operator for TouchDesigner, Powered by the Daydream API

Creator: Lyell Hintz (@dotsimulate)
Operator: StreamDiffusionTD
Backends Supported: Local + Daydream (Livepeer)
























0:00

/0:34


1√ó

















Overview

StreamDiffusionTD is a TouchDesigner operator that connects real-time inputs like audio, sensors, and camera feeds to StreamDiffusion, enabling live generative visuals controlled in real time. Wit`,
  reading_time: 2
},
{
  title: `Livepeer Incorporated! (and realtime AI)`,
  href: `https://blog.livepeer.org/livepeer-incorporated-and-realtime-ai/`,
  author: `By Livepeer Team`,
  content: `<p>Written by Doug Petkanics, Co-founder and CEO at Livepeer Inc</p><p>The past 18 months have been an energizing time to be in the Livepeer Ecosystem. An onchain treasury was introduced to fund public goods via community governance, the community has coalesced around Livepeer‚Äôs opportunity to be the leading infrastructure for realtime AI video, and fees and usage of the network have been steadily increasing due to this focus. The Livepeer Foundation has recently launched to steward the 10+ entities in the ecosystem that are core contributors to the project, and is unlocking even more funding around the opportunities recommended in <a href="https://forum.livepeer.org/t/advisory-boards-phase-1-strategic-pillars-2025/2999?ref=blog.livepeer.org"><u>the project‚Äôs strategic pillars</u></a>. </p><figure class="kg-card kg-image-card"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdTS98RtUcZGop616zTPF0dZQRB8ZxXty8-auuDunnQjz_tG7Nc0yG9p2oPGMTpU0tnA9hL1mQj11BAXCItPqFQg8pLto8RfPYY3O-5mUv11dkMG6P5PqXPJiopcz9m5pdMZMrOWQ?key=C-YUbwhjw3XbjtRFAKSsvQ" class="kg-image" alt="" loading="lazy" width="358" height="489"></figure><p>With so much core development, marketing, and growth driven by the ecosystem at large, the company that I co-founded and operate, Livepeer Incorporated, has had the opportunity to shift its focus to what we deem to be the highest priority area of the project where we feel uniquely suited to make an outsized impact: <strong>executing a high conviction go to market motion in an attempt to dramatically grow demand on the Livepeer network</strong>. We, like many in the ecosystem, are fully bought in to the realtime AI video vision laid out in <a href="https://mirror.xyz/livepeer.eth/bCruUtv0PJWWlFxfbCMATGM_h15hUncwvyFW1A3z7Ag?ref=blog.livepeer.org"><u>Livepeer Cascade</u></a>, and are solely focused on productization to find product market fit for the Livepeer network as the leading infrastructure in the coming world of live video AI. Here is a bit about what Livepeer Inc is focused on, and almost equally as importantly, what we are not focused on in the coming 12 months.</p><h2 id="product-market-fit-for-realtime-ai-video">Product Market Fit for Realtime AI Video&nbsp;</h2><p>As mentioned, the number one priority is to prove that the Livepeer network has product market fit as an infrastructure that runs the latest and greatest in realtime AI video workflows for developers. To do this, we‚Äôll focus on three core things:</p><ol><li>Contribute to core network development to ensure Livepeer is an infrastructure that can run realtime AI video workflows.</li><li>Build the developer APIs to run these workflows that developers use to build them into applications. This is a natural extension of <a href="http://livepeer.studio/?ref=blog.livepeer.org"><u>Livepeer Studio</u></a>.&nbsp;</li><li>Cultivate the leading realtime AI video community. Researchers, builders, and creators interested in this coming category need a home. They will provide the moat that ensures that an open, community led infrastructure will always be more responsive, cost effective, and full featured than centralized alternatives.</li></ol><p>We‚Äôre going to provide the full stack product, engineering, community, and go to market motion to validate product market fit for this opportunity. This will drive significant fees and growth into the Livepeer network. We‚Äôre aligned as large LPT token holders and want the network to succeed - which represents a far bigger opportunity for Livepeer Inc than any revenue related opportunity via SaaS services in the short term. Let‚Äôs grow those network fees!</p><h2 id="what-livepeer-inc-is-not-focused-on">What Livepeer Inc is Not Focused On</h2><p>While there are many potential products and go to markets that can be executed upon under an ambitious vision of being the world‚Äôs open video infrastructure, a single company is more likely to succeed by focusing on only one opportunity at a time. Many alternative demand generating bets will be better served by other self-motivated actors in the ecosystem - especially as the open source software around Livepeer, and the broader ecosystem has matured to the point of providing reliable access points for different categories of use cases.Regarding Livepeer Inc‚Äôs learnings on some of these categories: </p><ul><li>Transcoding alone has been proven out technically and economically, however the market hasn‚Äôt accepted the standalone infrastructure without significant productization, support, SLAs, and enterprise services around it.</li><li>Similarly, when bundled with end to end streaming, the offering isn‚Äôt significantly differentiated in a crowded and consolidating market.&nbsp;</li><li>Livepeer Studio will continue to support existing users at the enterprise level that pay for these surrounding services, while passing the transcoding jobs through to the Livepeer network, but due to the long sales cycle and slow growth, it will not be actively competing to grow this source of demand.&nbsp;</li><li>The ecosystem can support aspiring users of transcoding and streaming via projects like Streamplace, the Frameworks SPE, and their supporting teams. One of the core pillars of the Livepeer Foundation‚Äôs GTM recommendations is to tackle being the open video infrastructure for web3 social and decentralized streaming, so the ecosystem will prioritize support. This includes aspiring web3-centric streaming users, who culturally align with the values of the project community, but to date have not shown significant growth nor driven significant fees to the network. There‚Äôs an opportunity for these projects to crack this nut and help these users grow, if they deem it to be worth the effort!</li><li>There are also additional bets that the ecosystem is interested in around the realtime AI mission. <a href="https://forum.livepeer.org/t/advisory-boards-phase-1-5-gtm-strategy-2025/3019?ref=blog.livepeer.org"><u>These are laid out by the Livepeer Foundation‚Äôs GTM Strategy post</u></a>. Visual avatars for live AI agents is one example. Realtime video analysis and understanding are others. These areas do overlap with the broad theme that Livepeer Inc is focused on - running realtime AI models on live video on the Livepeer network. However as Inc pursues creative AI use cases initially to inspire the broader world in what‚Äôs possible, we welcome others in the ecosystem building commercial entities to go after these opportunities. And we will certainly collaborate. If the ecosystem efforts make technical progress, but stop short of commercializing and going to market, these are areas for collaboration with Inc to consider productizing for commercial purposes.&nbsp;</li></ul><h2 id="a-simplified-view-foundation-and-inc">A Simplified View: Foundation and Inc</h2><p>While the above contains a lot of details about realtime AI and specific demand generating bets on the Livepeer network, there‚Äôs a simplified view:</p><ul><li><strong>The Livepeer Foundation</strong> will steward the Livepeer community, project marketing, and public goods funding to enable recommendations on the project roadmap.</li><li><strong>Livepeer Inc </strong>will focus on driving demand to the network by building the realtime AI products, go to market services, and AI community - initially in the creative realtime AI video space.</li></ul><figure class="kg-card kg-image-card"><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdM0pspDREcAcvG-eb_w-H0Hnmxi1_-JYylo52vT5Vtaf2Hq10EQ6szkPmoKingVJjeOIsBm5OPPgmm9PlBxNv_54lSDSuP3dSQ1GTJXIaDqAYZaFHXuWvrLTGy2TlJFO97GdEJIw?key=C-YUbwhjw3XbjtRFAKSsvQ" class="kg-image" alt="" loading="lazy" width="624" height="364"></figure><p>If you‚Äôre interested in building within this ecosystem, there are lots of opportunities that both contribute to the core development and operations of the project in service of the realtime AI mission, but also to develop companies that service additional markets not currently being focused on. Hopefully the above post gives you a view into what some of those opportunities and gaps are. Then check out <a href="https://forum.livepeer.org/t/advisory-boards-phase-2-tactical-recommendations-2025/3025?ref=blog.livepeer.org"><u>the Livepeer Foundation‚Äôs recent forum posts on tactical recommendations</u></a>, and raise your hand to get involved in the ones of interest. </p><div class="kg-card kg-button-card kg-align-center"><a href="https://discord.com/invite/livepeer?ref=blog.livepeer.org" class="kg-btn kg-btn-accent">Join the Community</a></div>`,
  datePosted: `Jul 31, 2025`,
  img: `https://blog.livepeer.org/content/images/2025/07/e.png`,
  excerpt: `Written by Doug Petkanics, Co-founder and CEO at Livepeer Inc

The past 18 months have been an energizing time to be in the Livepeer Ecosystem. An onchain treasury was introduced to fund public goods via community governance, the community has coalesced around Livepeer‚Äôs opportunity to be the leading infrastructure for realtime AI video, and fees and usage of the network have been steadily increasing due to this focus. The Livepeer Foundation has recently launched to steward the 10+ entities in `,
  reading_time: 5
}
];